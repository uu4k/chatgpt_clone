from urllib.parse import urlparse
import streamlit as st
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)
from langchain.callbacks import get_openai_callback
import requests
from bs4 import BeautifulSoup

from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import YoutubeLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter



def init_page():
    st.set_page_config(
        page_title="My Great ChatGPT",
        page_icon="ğŸ£"
    )
    st.header("My Great ChatGPT ğŸ£")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]
        st.session_state.costs = []


def select_model():
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-3.5-16k", "GPT-4"))
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo-0613"
    if model == "GPT-3.5-16k":
        st.session_state.model_name = "gpt-3.5-turbo-16k-0613"
    else:
        # https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4
        # 20230817æ™‚ç‚¹ã§ã¯$1ä»¥ä¸Šã®èª²é‡‘ã—ã¦ãªã„ã®ã§ä½¿ãˆãªã„
        st.session_state.model_name = "gpt-4"

    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.01ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.01)

    # 300: æœ¬æ–‡ä»¥å¤–ã®æŒ‡ç¤ºã®tokenæ•° (æ±ºã‚ã†ã¡ã®é›‘ãªå®Ÿè£…ã§ã™â€¦)
    st.session_state.max_token = OpenAI.modelname_to_contextsize(st.session_state.model_name) - 300
    return ChatOpenAI(temperature=0, model_name=st.session_state.model_name)


def get_url_input():
    url = st.text_input("URL: ", key="input")
    return url


def validate_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def get_answer(llm, messages):
    with get_openai_callback() as cb:
        answer = llm(messages)
    return answer.content, cb.total_cost


def get_content(url):
    try:
        with st.spinner("Fetching Content ..."):
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')

            # main, articleã‚¿ã‚°ã‚ã‚Œã°ãã‚Œä½¿ã†
            if soup.main:
                return soup.main.get_text()
            elif soup.article:
                return soup.article.get_text()
            else:
                return soup.body.get_text()
    except:
        st.write('something wrong')
        return None


def build_prompt(content, n_chars=300):
    return f"""ä»¥ä¸‹ã¯ã¨ã‚ã‚‹Webãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã‚ã‚‹ã€‚å†…å®¹ã‚’{n_chars}ç¨‹åº¦ã§ã‚ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„

=======

{content[:1000]}

=======

æ—¥æœ¬èªã§æ›¸ã„ã¦ã­ï¼
"""

def get_document(url):
    with st.spinner("Fetching Content ..."):
        loader = YoutubeLoader.from_youtube_url(
            url, 
            add_video_info=True,
            language=['en', 'ja']
        )
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            model_name=st.session_state.model_name,
            chunk_size = st.session_state.max_token,
            chunk_overlap=0
        )
        return loader.load_and_split(text_splitter=text_splitter) # Documentå–å¾—

def summarize(llm, docs):
    prompt_template = """Write a concise Japanese summary of the following transcript of Youtube Video.
    
{text}

ã“ã“ã‹ã‚‰æ—¥æœ¬èªã§æ›¸ã„ã¦ã­ã€‚å¿…ãš3æ®µè½ä»¥å†…ã®200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨:
"""
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

    with get_openai_callback() as cb:
        chain = load_summarize_chain(
            llm,  # e.g. ChatOpenAI(temperature=0)
            chain_type="map_reduce",
            verbose=True,
            map_prompt=PROMPT,
            combine_prompt=PROMPT
        )
        response = chain({"input_documents": docs, "token_max": st.session_state.max_token}, return_only_outputs=True)
    return response['output_text'], cb.total_cost

def main():
    init_page()

    llm = select_model()
    init_messages()

    container = st.container()
    response_container = st.container()

    with container:
        url = get_url_input()
        is_valid_url = validate_url(url)

        if not is_valid_url:
            st.write('Please input valid url')
            output_text=None
        else:
            document = get_document(url)

            if document:
                with st.spinner("ChatGPT is typing ..."):
                    output_text, cost = summarize(llm, document)
                st.session_state.costs.append(cost)
            else:
                output_text = None

    if output_text:
        with response_container:
            st.markdown("## Summary")
            st.write(output_text)
            st.markdown("---")
            st.markdown("## Original Text")
            st.write(document)

    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in reversed(costs):
        st.sidebar.markdown(f"- ${cost:.5f}")


if __name__ == '__main__':
    main()
